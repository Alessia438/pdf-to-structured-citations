<!doctype html>
<html lang="en">
<head>
	<title>PDF to Structured Citations</title>
	<!-- Required meta tags -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
	<!-- Bootstrap CSS -->
	<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css" integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">
	<!-- Optional JavaScript -->
    <!-- jQuery first, then Popper.js, then Bootstrap JS -->
    <script src="https://code.jquery.com/jquery-3.2.1.slim.min.js" integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.9/umd/popper.min.js" integrity="sha384-ApNbgh9B+Y1QKtv3Rn7W3mgPxhU9K/ScQsAP7hUibX39j7fakFPskvXusvfa0b4Q" crossorigin="anonymous"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/js/bootstrap.min.js" integrity="sha384-JZR6Spejh4U02d8jOt6vLEHfe/JQGiRRSQQxSfFWpi1MquVdAyjUar5+76PVCmYl" crossorigin="anonymous"></script>
    <style type="text/css">
	body {
		margin: 0;
		font-family: "Nunito Sans", sans-serif;
		font-size: 1rem;
		font-weight: 300;
		line-height: 1.5;
		color: #565264;
		text-align: left;
		background-color: #D1C3BD;
	}
	button.btn-link{
		color: #565264;
		text-decoration: none;
		font-size: bold;
		text-decoration:none; 
	}

	button.btn-link:hover{
		color: #735F6B; 
		text-decoration:none; 
		cursor:pointer;  
	}
	.card-body{color: black;}
	.card {
		margin: 0 auto;
		float: none;
		margin-bottom: 10px;
	}
	ul li, ol li{text-align: left;}
	a.back-to-top.dark {
		margin: auto;
		padding-left: 30vw;
	}
	p{text-align:justify;}
	h1 {
	    font-family: Snell Roundhand;
	    text-align: center;
	    margin-top: 10vh;
	    font-size: xxx-large;
	}
    </style>
 
</head>
<body>
	<nav class="navbar navbar-expand-lg navbar-light bg-light">
	  <a class="navbar-brand">to_SCi</a>
	  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
	    <span class="navbar-toggler-icon"></span>
	  </button>
	  <div class="collapse navbar-collapse" id="navbarNav">
	    <ul class="navbar-nav">
	      <li class="nav-item">
	        <a class="nav-link" href="#">Home</a>
	      </li>
	      <li class="nav-item">
	        <a class="nav-link" href="https://github.com/Alessia438/pdf-to-structured-citations" target=”_blank”>GitHub_Repository</a>
	      </li>
	    </ul>
	  </div>
	</nav>

	<h1>PDF to structured citations</h1>
	
	<div id="accordion">

<!-- first card -->
<div class="card" style="width: 90vw; margin-top: 20vh;">
	    <div class="card-header" id="headingOne">
	      <h5 class="mb-0" style="text-align: center;">
	        <button class="btn btn-link" data-toggle="collapse" data-target="#collapseOne" aria-expanded="true" aria-controls="collapseOne">
	          Next meeting: Tuesday 05/11/2020 
	        </button>
	      </h5>
	    </div>

	    <div id="collapseOne" class="collapse show" aria-labelledby="headingOne" data-parent="#accordion">
	      <div class="card-body" style="text-align: center;">
	        <h3>RESEARCH</h3>
			<br>
			<h4>Features of Systematic Literature Reviews (Guidelines for performing Systematic Literature Reviews in Software Engineering)</h4>
				<p>Some of the features that differentiate a systematic review from a conventional expert literature review are:</p>
				<ol>
					<li>Systematic reviews start by defining a review protocol that specifies the research question being addressed and the methods that will be used to perform the review.</li>
					<li>Systematic reviews are based on a defined search strategy that aims to detect as much of the relevant literature as possible. </li>
					<li>Systematic reviews document their search strategy so that readers can assess their rigour and the completeness and repeatability of the process (bearing in mind that searches of digital libraries are almost impossible to replicate). </li>
					<li>Systematic reviews require explicit inclusion and exclusion criteria to assess each potential primary study.</li>
					<li>Systematic reviews specify the information to be obtained from each primary study including quality criteria by which to evaluate each primary study.</li>
				</ol>
			<br>
			<h4>Structure of a systematic review (Guidance on Conducting a Systematic Literature Review)</h4>
				<p>The articles proposes a structure for the research flow which is summarized by the following list:</p>
				<ol>
					<li>planning the review:</li>
						<ul>
						<li>identify the need for a review,</li>
						<li>specify research questions,</li>
						<li>develop a review protocol.</li>
						</ul>
					<li>conducting the review:</li>
						<ul>
						<li>identify and select primary studies, </li>
						<li>extract, analyze, and synthesize data. </li>
						</ul>
					<li>reporting the review: </li>
						<ul>
						<li>write the report to disseminate their findings from the literature review.</li>
						</ul>
				</ol>
				<p>In this moment the relevant part I am interested in is "planning the review". Indeed the first step in order to carry out a sistematic review, as stated in both the previous articles, is developing a protocol with some specifications defined in the articles themselves. Then, once finished, the protocol should be validated.</p> 

		       
		<h3>First draft of the protocol</h3>

		<h4>Purpose of the study:</h4>
		<p>A systematic literature review is necessary in order to obtain information about the softwares which allow data extraction from PDF file formats. The part of the text on which this software will be applied is the citations one. Therefore the objective of this research is that of retrieving the most suitable software for that purpose. </p>

		<h4>Research questions:</h4>
		<p>Which is the software whose features are the most suitable to retrieve references textual information from PDF files and translate them into structured data?</p>

		<h4>Inclusion criteria:</h4>
		<p>IC for search strategies:</p>
		<ul>
			<li>Languages: en, it;</li>
			<li>Publication date: not before 1993.</li>
		</ul>
		<p>IC for screening procedure:</p>
		<ul>
			<li>Quality criteria (still to define).</li>
		</ul>

		<h4>Search strategies:</h4>
		<p>Step 1 <i>(seed papers)</i>:</p>
		<ul>
			<li>Starting from seed papers, make backward and forward search;</li>
			<li>SEED PAPERS LIST: "Construction of the Literature Graph in Semantic Scholar"</li>
		</ul>
		<p>Step 2 <i>(keywords)</i>:</p>
		<ul>
			<li>keyword search through the most used and efficient platforms: Google Scholar, Web of Science, Lens, EBSCO, ProQuest, IEEE Xplore;</li>
			<li>forward e backward research on the papers retrieved with keywords. In particular the forward research has been carried out both manually and with the help of some platforms which have that specific functionality;</li>
			<li>KEYWORDS LIST: “PDF extractor”, “PDF extractor software”, “extraction of information from PDF”;</li>
			<li>PLATFORMS FOR FORWARD RESEARCH: Google Scholar, the ISI Citation Index.</li>
		</ul>
		<p>Step 3 <i>(stop criterion)</i>:</p>
		<ul>
			<li>When no new articles/papers/softwares are brought by new searches, stop the research.</li>
		</ul>
		<p>Step 4 <i>(first generic inclusion criteria)</i>:</p>
		<ul>
			<li>Keep the articles: </li>
			<ul>
				<li>retrieved with both generic and precise keywords (it allows );</li>
				<li>after title screening (absolute first check whether the topic of the article  is effectively related to the one I am interested in).</li>
			</ul>
			<li>Merge the articles and remove duplicates. </li>
		</ul>
		</p>
		<h4>Screening procedures: <i>(successively)</i></h4>
		<h4>Quality assessment criteria <i>(successively)</i></h4>
		<h4>Strategies for data extraction, synthesis, and reporting. <i>(successively)</i></h4>
		  <br>    
		<h3>BIBLIOGRAPHY</h3>
		    <ul>
			    <li><a href="https://doi.org/10.1177/0739456X17723971">Guidance on Conducting a Systematic Literature Review</a></li>
			    <li><a href="https://www.elsevier.com/__data/promis_misc/525444systematicreviewsguide.pdf">Kitchenham, B. A. & Charters, S. (2007). Guidelines for performing Systematic Literature Reviews in Software Engineering (EBSE 2007-001). Keele University and Durham University Joint Report.</a></li>
			</ul>
	      </div>
	    </div>
	  </div>
<!-- end of first card -->

<!-- last card -->
	<div class="card" style="width: 90vw; margin-top: 20vh;">
	    <div class="card-header" id="headingTwo">
	      <h5 class="mb-0" style="text-align: center;">
	        <button class="btn btn-link" data-toggle="collapse" data-target="#collapseTwo" aria-expanded="true" aria-controls="collapseTwo">
	          Next meeting: Tuesday 04/20/2020 
	        </button>
	      </h5>
	    </div>

	    <div id="collapseTwo" class="collapse" aria-labelledby="headingOne" data-parent="#accordion">
	      <div class="card-body" style="text-align: center;">
	        <h3>RESEARCH</h3>
		      <br>
		      <h4>How does ScienceParse work</h4>
		      <p>From the reading <a href="https://www.aclweb.org/anthology/N18-3011.pdf">Construction of the Literature Graph in Semantic Scholar</a> I have obtained information 
		      about a possible generic structure to give also to my work:</p>
		      <ol>
			      <li><b>Pre-processing of the data</b>: this first step consists of different passages which allow to transform the data in such a way that it is readable
			      by the software used to carry out the task;</li>
			      <li><b>Model</b>: it is organized the model which shall be passed from the following steps untill the final test;</li>
			      <li><b>Training</b>: train the software on a set of organized data proportioned with the final set;</li>
			      <li><b>Decoding</b>: decode the information obtained as output of the training phase to understand the quality of the results;</li>
			      <li><b>Final test</b>: test the software on a final smaller set of data to see if the predictions made by the spftware are reliable.</li>
		      </ol>
		      <p>From the notions reported in the article it has come out that there is in certain cases the need to make use of more than one software, each one for different
		      purposes. In the cited article, for instance the writers make use of 3 different ones in order to extract the titles, citations and authors: one to tokenize the
		      text, one for embedding the lowercase tokens and another to used the transformed data and carry out the final task (recognition of the paths).
		      From this article I have understood that I may try to look for a software with more features which allow to use less other external softwares to carry out the task.
		      </p>
		      <br>
		      <h4>Grobid</h4>
		      <p>GROBID definition:</p>
		      <ol>
			<li>GROBID is a machine learning library;</li>
			<li>it can extract, parse and re-structure raw documents such as PDF;</li>
			<li>it transforms raw information into structured XML/TEI encoded documents.</li>
			</ol>
		      <p>The following functionalities are available:</p>
			<ul>
				<li>References extraction and parsing. All the usual publication metadata are covered (including DOI, PMID, etc.).</li>
				<li>Citation contexts recognition and resolution to the full bibliographical references of the article.</li>
				<li>Parsing of names, in particular author names in references (distinct model from the header ones).</li>
				<li>Parsing of dates, ISO normalized day, month, year.</li>
				<li>Consolidation/resolution of the extracted bibliographical references using the biblio-glutton service or the CrossRef REST API.</li>
				<li>PDF coordinates for extracted information, allowing to create "augmented" interactive PDF.</li>
			</ul>
			<p>GROBID uses optionally Deep Learning models relying on the DeLFT library, a task-agnostic Deep Learning framework for sequence labelling and text classification.</p>
			<p>The advantage of Grobid from a computational point of view, is that it is available in three different programming languages Python, Java and Javascript (Node.js). 
				All these clients will take advantage of the multi-threading for scaling large set of PDF processing. </p>
			<p>A problem is that there is no certainty that it works on Windows system.</p>

		      <br>
		      <h4>EXCITE</h4>
		      <p>Excite is a project composed of different but dependent subsections:</p>
		      <ul>
				<li><a href=”https://github.com/exciteproject/Exparser”>Exparser</a>: to extract and segment the PDF citations;</li>
				<li><a href=”https://github.com/exciteproject/EXmatcher”>EXmatcher</a>: dedicated to the task of citation matching in EXCITE;</li>
				<li><a href=”https://github.com/exciteproject/EXpublisher”>EXpublisher</a>: is dedicated to the task of converting EXCITE Data to a JSON file with OCC ontology;</li>
				<li><a href=”https://github.com/exciteproject/EXgoldstandard”>EXgoldstandard</a>: created for the evaluation and training of EXmatcher and EXparser.</li>
			</ul>
			<p>The language is mainly python and it has the advantage of having in itself all the passages required to test and use the software 
				(it seems that it does not require external systems to make parts of the job like with ScienceParse).</p>
			<p><a href=”https://github.com/exciteproject/papers”>Here</a> are the related bibliographic papers (which I have to read to better understand how Excite works).</p>
			
		      <h4>Retrieved Softwares</h4>
		      <ul>
			      <li>Parsers</li>
					<ul>
						<li><a href="https://github.com/allenai/allennlp"><b>ScienceParse</b></a> is able to parse scientific papers and return them in structured form;</li>
						<li><a href="https://github.com/kermitt2/grobid"><b>Grobid</b></a> for extracting, parsing and re-structuring raw documents into structured XML/TEI encoded documents;</li>
						<li><a href="https://github.com/exciteproject/"><b>EXparser (EXCITE)</b></a> is a tool for extracting and segmenting reference strings from PDF documents. It is provided by the project EXCITE.</li>
					</ul>
			
			      <li>Others</li>
					<ul>
						<li><a href="https://pdfbox.apache.org/"><b>Apache’s PDFBox</b></a> to tokenize the text of each single PDF page;</li>
						<li><a href="https://nlp.stanford.edu/projects/glove/"><b>GloVe</b></a> to embed the lowercase tokens.</li>
					</ul>
			</ul>
		    <br>  
		<h3>METHODOLOGY</h3>
		      <ol>
			<li> As first passage look for literature letting me understand which are the main steps I’ll have to take into account for working with pdf data extraction 
			     (e.g. if I have to use one or more softwares, in which passages the software(s) is/are required); </li>
			<li>Use the scientific paper citations to look for correlated paper, only in a first phase in order to begin to understand the constraints of the research I am making;</li>
			<li>look for some relevant parsers (and eventually other softwares required in order to carry out correlated tasks) and in a second moment look to each single system and find 
				out the most relevant features and compare them. If I am not satisfied by the ones I have retrieved up to that moment I continue looking for other softwares.</li>
			<li>parameters to classify the softwares:</li>
			        <ul>
				<li>programming language (up to now java e python);</li>
				<li>number of features and need for other softwares;</li>
				<li>operating systems for which it is available (?);</li>
				<li>other (?).</li>
				</ul>
			</ol>
		  <br>    
		<h3>BIBLIOGRAPHY</h3>
		      <ul>
			      <li><a href="https://www.aclweb.org/anthology/N18-3011.pdf">Construction of the Literature Graph in Semantic Scholar</a></li>
			    <li><a href="https://arxiv.org/abs/1802.08301">Content-Based Citation Recommendation</a></li>
			     <li><a href="https://www.aaai.org/Papers/Workshops/2007/WS-07-14/WS07-14-006.pdf">Author Disambiguation Using Error-driven Machine Learning with a Ranking Loss Function</a></li>
			     <li><a href="https://ieeexplore.ieee.org/document/7991559"> Luca Weihs and Oren Etzioni. 2017. Learning to predict citation-based impact measures. In JCDL.</a></li>
			      <li><a href="https://aaai.org/ocs/index.php/WS/AAAIW15/paper/view/10185/10244">Marco Valenzuela, Vu Ha, and Oren Etzioni. 2015. Identifying meaningful citations. In AAAI Workshop (Scholarly Big Data).</a></li>
		     <li><a href="http://slides.com/janagelavik/grobid#/3">GROBID in 30 slides - GROBID Documentation</a></li>
			      <li><a href="https://grobid.readthedocs.io/en/latest/grobid-04-2015.pdf">Grobid, Metadata extraction from PDF documents using machine learning tools in INSPIRE-HEP</a></li>
			</ul>
	      </div>
	    </div>
	  </div>
<!-- end of last card -->
		
	</div>
	
	

<div class="d-flex align-items-center p-4 neutral-1-bg-a8">
  <a href="#" aria-hidden="true" data-attribute="back-to-top" class="back-to-top dark">
    <svg class="bi bi-arrow-up-square" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" d="M8 15a.5.5 0 0 0 .5-.5V2.707l3.146 3.147a.5.5 0 0 0 .708-.708l-4-4a.5.5 0 0 0-.708 0l-4 4a.5.5 0 1 0 .708.708L7.5 2.707V14.5a.5.5 0 0 0 .5.5z"/></svg>
  </a>
</div>

</body>
</html>
